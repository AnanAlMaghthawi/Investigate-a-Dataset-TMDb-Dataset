{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Project: Investigate a Dataset - [TMDb Dataset]\n",
    "\n",
    "## Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#intro\">Introduction</a></li>\n",
    "<li><a href=\"#wrangling\">Data Wrangling</a></li>\n",
    "<li><a href=\"#eda\">Exploratory Data Analysis</a></li>\n",
    "<li><a href=\"#conclusions\">Conclusions</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "### Dataset Description \n",
    "\n",
    "> In this section of the report, we provide a brief introduction to the dataset we've selected for The analysis.\n",
    "The selected file to be analyzed is named tmdb-movies.csv provided by Kaggle, it contains information about 10,000 movies collected from The Movie Database (TMDb),including user ratings and revenue. in this report, we would invistegate more interesting patterns and insights. \n",
    "\n",
    "\n",
    "\n",
    "### Question(s) for Analysis\n",
    ">In order to understand the dataset and looking for  the hidden insights, we pose many question as following: \n",
    ">1)Which genres are most popular over Years? \n",
    ">2)which years have the  most movies releases?\n",
    ">3)What are the 5 Top production Companies?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell, we set up several statements for Importing all analysis related packages.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as snb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='wrangling'></a>\n",
    "## Data Wrangling\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### General Properties\n",
    "> in this section we will explore the data at hand.\n",
    "One option that you can take with this project is to do a lot of explorations in an initial notebook. These don't have to be organized, but make sure you use enough comments to understand the purpose of each code cell. Then, after you're done with your analysis, create a duplicate notebook where you will trim the excess and organize your steps so that you have a flowing, cohesive report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here in this cell, we will Load data and print out a few lines using the folloing statements.\n",
    "df=pd.read_csv('Database_TMDb_movie_data/tmdb-movies.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#exploring data properities(shape)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> as seen, the data consists of more than 10K movies and 21 attributes(columns) with various information about each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">to have a clear vision on the dataset , we showed the data structure by exploring the attributes of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We would like to describe the basic features of the data to give a better understanding of the behavior/pattern of data, how it looks like and how spread out it is. Therefor, we explored -As shown above- data statistic like mean, mode, standard deviation.\n",
    "\n",
    ">as we see, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data Preparation &  Cleaning\n",
    "> The dataset was not ready for analysis. So, we need to check the shortcoming if any, then prepare the data by cleaning, handling the missing values, remove some irrelative attributes, and divide others. However, based on our understanding of the data, we deleted some rows that contained wrong,or useless values we will discuss it later.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) removing duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# checking if there is an duplications\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> there is one duplication case in rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to deal with this duplication, we will drop the duplicated row\n",
    "df= df.drop_duplicates(keep='first')\n",
    "#checking again to ensure the duplicated row is dropped \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#checking if there is and missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">As. we can see above, there are  about 10,609 missing values  that are distributed in 9 columons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#to deal with the missing values, we need replace those values with Zero by using (filna) function\n",
    "df1=df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Attributes omission\n",
    "we decided to remove some attributes from our analysis because they are irrelevant "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The irrelevant attributes (columns) such as imdb_id, homepage,tagline, overview, budget_adj and revenue_adj, so we will drop theses attributes\n",
    "df.drop(['imdb_id','homepage','tagline','overview','budget_adj','revenue_adj'],axis =1,inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> So far, we had done many steps. We first collected the dataset as CSV file, we started to got a quick look of the data, then we explored the general propertities of the data, we showed its structure or dimensions, and we figured out basic statistics to have a better understanding of data. \n",
    "After initial exploration the data, we had done several preprocessing and preparations techniques like; 1-checking any shortcomings in the data in terms of there is any duplication, missing values, and deal with it.2- attribute omission, we removed all irrelevent columns from our analysis.        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eda'></a>\n",
    "## Exploratory Data Analysis\n",
    "\n",
    "> Now after we have done many preprocessing techniqes, ou dataset is ready for exploration in order to look for variables dependencies, examin the relationships between the given data attributes using through certain statistics tests and support these results with visulizations. To start in this stage, we have to state several research questions. these questions will be defined in the following; \n",
    "\n",
    ">Note that at least two or more kinds of plots should be created as part of the exploration, and you must  compare and show trends in the varied visualizations. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Which genres are most popular over Years? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since each has multiple genres seperated with '|', we will split the string by writing the following function, and count each genr\n",
    "def data (splt_gnr):\n",
    "# we will include all stated gerns of each row.\n",
    "    data_plot = df[splt_gnr].str.cat(sep = '|')\n",
    "    data = pd.Series(data_plot.split('|'))\n",
    "    info = data.value_counts(ascending=False)\n",
    "    return info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum_genre_movies = data('genres')\n",
    "print(sum_genre_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we are going to visualize the movies gerns distribution using plot function\n",
    "sum_genre_movies.plot(kind='bar', figsize= (14,6), fontsize=15)\n",
    "#we will define the plot's title and label.\n",
    "plt.title(\"Most popular released movies' Genrs\",fontsize=16)\n",
    "plt.xlabel(' Total Movies',fontsize=15)\n",
    "plt.ylabel(\"Genres\",fontsize= 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">As presented above, the most popular movies'genres is Drama, Comedy, and Thriller, and action. this can give us a preception that the greatest audiance of these movies  are young group\n",
    ">the lowest popularity is Western movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### which years have the  most movies releases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#now we are going to visualize the highst year according movies release\n",
    "count_release=df['release_year'].value_counts().sort_index()\n",
    "count_release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#we would creat a plot that present the count total releases in each year as following\n",
    "count_release.plot(x='release_year',kind='bar',figsize=(14,6),fontsize = 15)\n",
    "# here we set plot labels and titles.\n",
    "plt.title(' Number Of Movie Releases by Years',fontsize = 15)\n",
    "plt.xlabel('Year',fontsize = 15)\n",
    "plt.ylabel('Number Of Releases',fontsize = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can use another type plot Line chart)\n",
    "count_release.plot(x = np.arange(1960,2016,5))\n",
    "snb.set(rc={'figure.figsize':(14,6)})\n",
    "plt.title(\" Number Of Movies per Years\",fontsize = 16)\n",
    "plt.xlabel('Year of Release',fontsize = 15)\n",
    "plt.ylabel('Number Of Movies',fontsize = 15)\n",
    "#setting style\n",
    "snb.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the overall releases trend is increasing through years which can be intepreted by the increases of film-making industry and demand ingreasing. However, 2014 has the largest number of movies releases. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the 5 Top production Companies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the companies are seperated with \"|\", so fist we need to split it  \n",
    "pc= df['production_companies'].str.get_dummies(sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppc=pc[pc.columns].apply(lambda x: sum(x.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting pie chart \n",
    "ppc.sort_values(0,ascending=False).head(5).plot.pie(autopct='%1.1f%%',shadow=True,frame=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### as we can see from the pie chart, the top 5 Production Companies are as following:\n",
    "1,Universal Pictures with 25.9% of total produced movies.\n",
    "2,Warner Bros with 16.9% of total produced movies.\n",
    "3,Paramoint Pictures wit 14.3% of total produced movies.\n",
    "4,Twentieth Century Fox Firm Corporation with 9.4% of total produced movies.\n",
    "5,Colombia Pictures with 9.1% of total produced movies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "## Conclusions\n",
    "\n",
    "> In conclusion, this project contains a practical exercise of data investigation process and an understanding of the basics of data discovery step should every data analyst considers.  \n",
    "Regarding our dataset(The Movies Database) We have done many steps during the ivestigation;\n",
    "data describtion: we set some questions for help us investigate our data, \n",
    "Data wrangling: we xplored some issues in the data that affet its readiness for the analysis, therefore, we have done many steps in data wrangling like; 1)removing one duplicated value, 2)handling over than 100,600 missing values,3) attribute omission; where we removed irrelevant columns like; 'imdb_id','homepage','tagline','overview','budget_adj','revenue_adj'.\n",
    "\n",
    "\n",
    "\n",
    ">In terms of the Exploratory Data Analysis phase .we can conclude our finding of the stated questions in the following: \n",
    "The most movie genres preferred by the audience are drama, comedy, and thriller.\n",
    "With regard to the number of films produced, we find that the most years in which the years were released are 2014 and 2015, followed by 2015.\n",
    "Another observation we found, is that the trend of movies releases has been clearly increasing over the years, and this comes with the development of the film industry and the demand for it.\n",
    "Finally, most of the film-making companies are depicted in a pie chart as shown above.\n",
    "\n",
    "### Regarding the limitations,  \n",
    ">we faced it was during the data cleaning process, the null values was a limitation. since we couldn't drop the rows that contains null values but it will affect the overall analysis. this led me to replace it with Zero. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import call\n",
    "call(['python', '-m', 'nbconvert', 'Investigate_a_Dataset.ipynb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
